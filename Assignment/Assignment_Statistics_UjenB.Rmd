### Importing required library

library(matlib)
library(visdat)
library(ggplot2)
library(glmnet)
library(rsample)
library(MASS)

#Reading CSV File#

customer_shopping_data <- read.csv("customer_shopping_data_1695379411426.csv")

#Understanding dataset#

head(customer_shopping_data)

tail(customer_shopping_data)

summary(customer_shopping_data)


# Check for missing values in the entire data frame
missing_values <- is.na(customer_shopping_data)

# Summarize the number of missing values in each column
missing_count <- colSums(missing_values)
print(missing_count)

unique_genders <- unique(customer_shopping_data$gender)
print(unique_genders)

unique_category <- unique(customer_shopping_data$category)
print(unique_category)

unique_payment_method <- unique(customer_shopping_data$payment_method)
print(unique_payment_method)

unique_shopping_mall <- unique(customer_shopping_data$shopping_mall)
print(unique_shopping_mall)

# Convert gender to numerical values
customer_shopping_data$gender <- as.numeric(factor(customer_shopping_data$gender, levels = unique(customer_shopping_data$gender)))

# Convert category to numerical values
customer_shopping_data$category <- as.numeric(factor(customer_shopping_data$category, levels = unique(customer_shopping_data$category)))

# Convert payment_method to numerical values
customer_shopping_data$payment_method <- as.numeric(factor(customer_shopping_data$payment_method, levels = unique(customer_shopping_data$payment_method)))

# Convert shopping_mall to numerical values
customer_shopping_data$shopping_mall <- as.numeric(factor(customer_shopping_data$shopping_mall, levels = unique(customer_shopping_data$shopping_mall)))

head(customer_shopping_data)

# define input
x <- customer_shopping_data[, !(names(customer_shopping_data) %in% c("invoice_no","customer_id","quantity", "invoice_date", "gender", "shopping_mall"))]
x 



# Convert invoice_date to Date format if not already done
customer_shopping_data$invoice_date <- as.Date(customer_shopping_data$invoice_date, format="%d/%m/%Y")

# Create a time series object with monthly frequency (assuming data is monthly)
customer_shopping_data.ts <- ts(x, 
                            start = c(as.numeric(format(min(customer_shopping_data$invoice_date), "%Y")), 
                                      as.numeric(format(min(customer_shopping_data$invoice_date), "%m"))), 
                            end = c(as.numeric(format(max(customer_shopping_data$invoice_date), "%Y")), 
                                    as.numeric(format(max(customer_shopping_data$invoice_date), "%m"))), 
                            frequency = 12)  # Monthly data, so frequency is 12

# Plot the time series of input x with one-month interval
plot(customer_shopping_data.ts, main = "Time series plot of Input", 
     xlab = "Invoice Date", ylab = "X (inputs)")

# Plot the time series of output y
# Convert invoice_date to Date format if not already done
customer_shopping_data$invoice_date <- as.Date(customer_shopping_data$invoice_date, format="%d/%m/%Y")
unique_dates <- unique(format(customer_shopping_data$invoice_date, "%Y-%m"))
# Create a time series object with monthly frequency (assuming data is monthly)
customer_shopping_data.ts <- ts(customer_shopping_data$quantity, 
                            start = c(as.numeric(format(min(customer_shopping_data$invoice_date), "%Y")), 
                                      as.numeric(format(min(customer_shopping_data$invoice_date), "%m"))), 
                            end = c(as.numeric(format(max(customer_shopping_data$invoice_date), "%Y")), 
                                    as.numeric(format(max(customer_shopping_data$invoice_date), "%m"))), 
                            frequency = 12)  # Monthly data, so frequency is 12
 
plot(customer_shopping_data.ts, main = "Time series plot of Output", 
     xlab = "Invoice Date", ylab = "Y (output) or Total Quantity")



#Distribution#

dis=density(x$price)
plot(dis,main = "Density plot of price")

# Creating a Histogram of X Inputs
hist(x$price,freq = FALSE,main="Histogram and density plot of price",xlab = "Price")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$price))


dis=density(x$payment_method)
plot(dis,main = "Density plot of whole inputs")

# Creating a Histogram of X Inputs
hist(x$payment_method,freq = FALSE,main="Histogram and density plot of payment Method",xlab = "Payment Method")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$payment_method))

dis=density(x$age)
plot(dis,main = "Density plot of whole inputs")

# Creating a Histogram of X Inputs
hist(x$age,freq = FALSE,main = "Histogram and density plot of age")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$age))

dis=density(x$category)
plot(dis,main = "Density plot of whole inputs")

# Creating a Histogram of X Inputs
hist(x$category,freq = FALSE,main = "Histogram and density plot of category")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$category))


dis=density(customer_shopping_data$quantity)
plot(dis,main = "Density plot of whole inputs")

# Creating a Histogram of X Inputs
hist(customer_shopping_data$quantity,freq = FALSE,main = "Histogram and density plot of Quantity")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$customer_shopping_data$quantity))


# Plotting age against quantity
Y <- customer_shopping_data$quantity
plot(x$age,Y,main = "Correlation between age and quantity signal", xlab = "age", ylab = "quantity" )

plot(x$price,Y,main = "Correlation between price and quantity signal", xlab = "price", ylab = "quantity" )

plot(x$category,Y,main = "Correlation between category and quantity signal", xlab = "category", ylab = "quantity" )

plot(x$payment_method,Y,main = "Correlation between payment_method and quantity signal", xlab = "payment_method", ylab = "quantity" )

#X = x
x$quantity <- customer_shopping_data$quantity
cor(x)
plot(x)

#Task 2
x$X1 <- x$age
x$X2 <- x$category
x$X3 <- x$price
x$X4 <- x$payment_method

x <- x[, c("X1", "X2", "X3", "X4")]
x <- as.matrix(x)
y <- as.matrix(customer_shopping_data$quantity)

# Calculating ones for binding the data
ones = matrix(1 , length(x)/4,1)
ones
#Task 2.1
#Calculating thetahat of Model 1
#Binding data from equation of model 1.
X_model1<-cbind(ones,(x[,"X4"]),(x[,"X1"])^2,(x[,"X1"])^3,(x[,"X3"])^4)
ridge_model1 <- glmnet(X_model1, Y, alpha = 0)  # Alpha = 0 for Ridge
Model1_thetahat <- coef(ridge_model1)
print(Model1_thetahat)

#Model 2
#Binding data from equation of model 2.
X_model2<-cbind(ones,(x[,"X3"])^3,(x[,"X3"])^4)
ridge_model2 <- glmnet(X_model2, Y, alpha = 0)  # Alpha = 0 for Ridge
Model2_thetahat <- coef(ridge_model2)
Model2_thetahat

#For model 3
#Binding data from equation of model 3.
X_model3<-cbind(ones,x[,"X2"],(x[,"X1"])^3,(x[,"X3"])^4)
ridge_model3 <- glmnet(X_model3, Y, alpha = 0)  # Alpha = 0 for Ridge
Model3_thetahat <- coef(ridge_model3)
Model3_thetahat

#For model 4
#Binding data from equation of model 4.
X_model4<-cbind(ones,x[,"X4"],x[,"X1"]^3,x[,"X3"]^4)
ridge_model4 <- glmnet(X_model4, Y, alpha = 0)  # Alpha = 0 for Ridge
Model4_thetahat <- coef(ridge_model4)
Model4_thetahat

#Binding data from equation of model 5.
X_model5<-cbind(ones,x[,"X4"],x[,"X1"]^2,x[,"X1"]^3,x[,"X3"]^4,x[,"X1"]^4)
ridge_model5 <- glmnet(X_model5, Y, alpha = 0)  # Alpha = 0 for Ridge
Model5_thetahat <- coef(ridge_model5)
Model5_thetahat

##Task 2.2
lambda <- 1
# Calculate predicted values for the ridge regression model
Y_hat_ridge1 <- predict(ridge_model1, s = lambda, newx = X_model1)
# Calculate residuals
residuals_ridge <- y - Y_hat_ridge1
# Calculate RSS for the ridge regression model
RSS_ridge <- sum(residuals_ridge^2)
# Extract coefficients for the specified lambda
coefficients_ridge <- coef(ridge_model1, s =lambda)
# Map coefficients to the corresponding columns of model1
Y_hat_m1 <- as.matrix(X_model1) %*% coefficients_ridge[-1]  # Exclude the intercept term
# Calculate RSS for Model 1
residuals_m1 <- y - Y_hat_m1
RSS_Model_1 <- sum(residuals_m1^2)
print(RSS_Model_1)

#model2
Y_hat_ridge2 <- predict(ridge_model2, s = lambda, newx = X_model2)
residuals_ridge <- y - Y_hat_ridge2
RSS_ridge <- sum(residuals_ridge^2)
coefficients_ridge <- coef(ridge_model2, s =lambda)
Y_hat_m2 <- as.matrix(X_model2) %*% coefficients_ridge[-1]  
residuals_m2 <- y - Y_hat_m2
RSS_Model_2 <- sum(residuals_m2^2)
print(RSS_Model_2)

#model3
Y_hat_ridge3 <- predict(ridge_model3, s = lambda, newx = X_model3)
residuals_ridge <- y - Y_hat_ridge3
RSS_ridge <- sum(residuals_ridge^2)
coefficients_ridge <- coef(ridge_model3, s =lambda)
Y_hat_m3 <- as.matrix(X_model3) %*% coefficients_ridge[-1]  
residuals_m3 <- y - Y_hat_m3
RSS_Model_3 <- sum(residuals_m3^2)
print(RSS_Model_3)

#model4
Y_hat_ridge4 <- predict(ridge_model4, s = lambda, newx = X_model4)
residuals_ridge <- y - Y_hat_ridge4
RSS_ridge <- sum(residuals_ridge^2)
coefficients_ridge <- coef(ridge_model4, s =lambda)
Y_hat_m4 <- as.matrix(X_model4) %*% coefficients_ridge[-1]  
residuals_m4 <- y - Y_hat_m4
RSS_Model_4 <- sum(residuals_m4^2)
print(RSS_Model_4)

#model5
Y_hat_ridge5 <- predict(ridge_model5, s = lambda, newx = X_model5)
residuals_ridge <- y - Y_hat_ridge5
RSS_ridge <- sum(residuals_ridge^2)
coefficients_ridge <- coef(ridge_model5, s =lambda)
Y_hat_m5 <- as.matrix(X_model5) %*% coefficients_ridge[-1]  
residuals_m5 <- y - Y_hat_m5
RSS_Model_5 <- sum(residuals_m5^2)
print(RSS_Model_5)

### Task 2.3 Calculating likelihood and Variance of each model
N=length(Y)
#Calculating the Variance of Model 1
Variance_model1=RSS_Model_1/(N-1)
Variance_model1
#Calculating the log-likelihood of Model 1
likehood_Model_1=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model1))-(1/(2*Variance_model1))*RSS_Model_1
likehood_Model_1
#Calculating Variance and log-likelihood of Model 2
Variance_model2=RSS_Model_2/(N-1)
Variance_model2
likehood_Model_2=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model2))-(1/(2*Variance_model2))*RSS_Model_2
likehood_Model_2
#Calculating Variance and log-likelihood of Model 3
Variance_model3=RSS_Model_3/(N-1)
Variance_model3
likehood_Model_3=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model3))-(1/(2*Variance_model3))*RSS_Model_3
likehood_Model_3
#Calculating Variance and log-likelihood of Model 4
Variance_model4=RSS_Model_4/(N-1)
Variance_model4
likehood_Model_4=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model4))-(1/(2*Variance_model4))*RSS_Model_4
likehood_Model_4
#Calculating Variance and log-likelihood of Model 5
Variance_model5=RSS_Model_5/(N-1)
Variance_model5
likehood_Model_5=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model5))-(1/(2*Variance_model5))*RSS_Model_5
likehood_Model_5


### Task 2.4 Calculating AIC And BIC of Each model
##Calculating AIC and BIC of model 1
K_model1<-length(Model1_thetahat)
K_model1
AIC_model1=2*K_model1-2*likehood_Model_1
AIC_model1
BIC_model1=K_model1*log(N)-2*likehood_Model_1
BIC_model1
## thetahat of model 2
K_model2<-length(Model2_thetahat)
K_model2
##Calculating AIC and BIC of model 2
AIC_model2=2*K_model2-2*likehood_Model_2
AIC_model2
BIC_model2=K_model2*log(N)-2*likehood_Model_2
BIC_model2
## thetahat of model 3
K_model3<-length(Model3_thetahat)
K_model3
##Calculating AIC and BIC of model 3
AIC_model3=2*K_model3-2*likehood_Model_3
AIC_model3
BIC_model3=K_model3*log(N)-2*likehood_Model_3
BIC_model3
## thetahat of model 4
K_model4<-length(Model1_thetahat)
K_model4
##Calculating AIC and BIC of model 4
AIC_model4=2*K_model4-2*likehood_Model_4
AIC_model4
BIC_model4=K_model4*log(N)-2*likehood_Model_4
BIC_model4
## thetahat of model 5
K_model5<-length(Model5_thetahat)
K_model5
##Calculating AIC and BIC of model 5
AIC_model5=2*K_model5-2*likehood_Model_5
AIC_model5
BIC_model5=K_model5*log(N)-2*likehood_Model_5
BIC_model5



## Task 2.5
## Error of model1
model1_error <- Y-Y_hat_m1
## Plotting the graph QQplot and QQ line of model 1
qqnorm(model1_error, col = "darkcyan",main = "QQ plot of model 1")
qqline(model1_error, col = "red",lwd=1)

## Error of model2
model2_error <- Y-Y_hat_m2 # error of model 2
## Plotting QQplot and QQ line of model 2
qqnorm(model2_error, col = "darkcyan",main = "QQ plot of model 2")
qqline(model2_error, col = "red")

## Error of model3
model3_error <- Y- Y_hat_m3
## Plotting QQplot and QQ line of model 3
qqnorm(model3_error, col = "darkcyan",main = "QQ plot of model 3")
qqline(model3_error, col = "red")

## Error of model4
model4_error <- Y-Y_hat_m4
## Plotting QQplot and QQ line of model 4
qqnorm(model4_error, col = "darkcyan",main = "QQ plot of model 4")
qqline(model4_error, col = "red")

## Error of model5
model5_error <- Y- Y_hat_m5
## Plotting QQplot and QQ line of model 5
qqnorm(model5_error, col = "darkcyan",main = "QQ plot of model 5")
qqline(model5_error, col = "red")


### Task 2.7
## Spliting the data of y into 2 form i.e. Traning and testing data set.
set.seed(123)
split_Y<-initial_split(data = as.data.frame(Y),prop=.7)
## Traning Y data split
Y_training_set<-training(split_Y)
Y_testing_set<-as.matrix(testing(split_Y))
## Testing Y data split
Y_training_data<-as.matrix(Y_training_set)
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_X<-initial_split(data = as.data.frame(x),prop=.7)
## Traning X data split
X_training_set<-training(split_X)
## Testing X data split
X_testing_set<-as.matrix(testing(split_X))
X_testing_data<-as.matrix(X_testing_set)
X_training_data<-as.matrix(X_training_set)
### Estimating model parameters using Traning set
traning_ones=matrix(1 , length(X_training_set$X1),1)
X_traning_model<-cbind(traning_ones,X_training_set[,"X2"],(X_training_set[,"X1"])^3,(X_training_set[
,"X3"])^4)
traning_thetahat <- ginv(t(X_traning_model) %*% X_traning_model) %*% t(X_traning_model) %*%Y_training_data
traning_thetahat

### Model out/Prediction
Y_testing_hat = X_testing_data %*% traning_thetahat
Y_testing_hat
RSS_testing=sum((Y_testing_set-Y_testing_hat)^2)
RSS_testing
t.test(Y_training_data, mu=500, alternative="two.sided", conf.level=0.95)
C_I1=-2.996730
C_I2=3.017749
p2 <- plot(density(Y_training_data), col="blue", lwd=2,
main="Distribution of Training Data")
abline(v=C_I1,col="red", lty=2)
abline(v=C_I2,col="red", lty=2)
thetaHat_training =solve(t(X_training_data) %*% X_training_data) %*% t(X_training_data) %*%
Y_training_data
thetaHat_training
length(thetaHat_training)
dis_test=density(Y_training_data)
plot((dis_test))
plot(dis_test,main = "Density plot of Y Signal")

### Calculating Confidential interval
z=1.96 ##(95%) Confidential interval
error=((Y_testing_set-Y_testing_hat))
n_len=length(Y_testing_hat)
C_I_1= z * sqrt( (error * (1-error) ) / n_len)
C_I_1
C_I_2= z* sqrt( (error * (1+error) )/ n_len)
C_I_2

##Task 3
## Model 2 will be used, parameter are selected and kept constant.
arr_1=0
arr_2=0
f_value=0
s_value=0
Model2_thetahat
#values from thetahat
thetebias <- 0.448299550 #choosen parameter
thetaone <- 0.038109255 # chosen prarameter
thetatwo <- 0.009827804 # constant value
thetafour <- 0.002092558 # constant value
Epison <- RSS_Model_2 * 2 ## fixing value of eplision
num <- 100 #number of iteration
##Calculating Y-hat for performing rejection ABC
counter <- 0
for (i in 1:num) {
range1 <- runif(1,-0.448299550,0.448299550) # calculating the range
range1
range2 <- runif(1,-0.038109255,0.038109255)
New_thetahat <- matrix(c(range1,range2,thetatwo,thetafour))
New_Y_Hat <- X_model2 %*% New_thetahat ## New Y hat
new_RSS <- sum((Y-New_Y_Hat)^2)
new_RSS
if (new_RSS > Epison){
arr_1[i] <- range1
arr_2[i] <- range2
counter = counter+1
f_value <- matrix(arr_1)
s_value <- matrix(arr_2)
}
}
hist(f_value)
hist(s_value)


###ploting the graph
plot(f_value,s_value, col = c("red", "blue"), main = "Joint and Marginal Posterior Distribution")